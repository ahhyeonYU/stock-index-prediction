{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "from feature_selection import get_data\n",
    "import FinanceDataReader as fdr\n",
    "import datetime\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#plt.rcParams['font.family'] = 'NanumGothic'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "weight_name = os.path.join('tmp_checkpoint.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, scaler_kospi = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>한국은행_기준금리</th>\n",
       "      <th>KOSPI</th>\n",
       "      <th>KOSDAQ</th>\n",
       "      <th>CD_91일</th>\n",
       "      <th>국고채_10년</th>\n",
       "      <th>회사채_3년_AA</th>\n",
       "      <th>KOSPI_거래대금_일평균</th>\n",
       "      <th>KOSDAQ_거래대금_일평균</th>\n",
       "      <th>KOSPI_주가이익비율_3</th>\n",
       "      <th>기관투자자_순매수</th>\n",
       "      <th>개인_순매수</th>\n",
       "      <th>투자자_예탁금</th>\n",
       "      <th>파생상품거래_예수금_1</th>\n",
       "      <th>RP</th>\n",
       "      <th>위탁매매_미수금</th>\n",
       "      <th>신용융자_잔고_2</th>\n",
       "      <th>거래대금_일평균_CALL_옵션</th>\n",
       "      <th>거래대금_일평균_PUT_옵션</th>\n",
       "      <th>KOSPI_BINARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.150785</td>\n",
       "      <td>0.523719</td>\n",
       "      <td>0.651852</td>\n",
       "      <td>0.905858</td>\n",
       "      <td>0.557803</td>\n",
       "      <td>0.133986</td>\n",
       "      <td>0.128401</td>\n",
       "      <td>0.110236</td>\n",
       "      <td>0.660705</td>\n",
       "      <td>0.172458</td>\n",
       "      <td>0.080661</td>\n",
       "      <td>0.019894</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.994870</td>\n",
       "      <td>0.005722</td>\n",
       "      <td>0.212613</td>\n",
       "      <td>0.125723</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.138142</td>\n",
       "      <td>0.512937</td>\n",
       "      <td>0.670370</td>\n",
       "      <td>0.843096</td>\n",
       "      <td>0.533237</td>\n",
       "      <td>0.073347</td>\n",
       "      <td>0.090498</td>\n",
       "      <td>0.108993</td>\n",
       "      <td>0.721468</td>\n",
       "      <td>0.211550</td>\n",
       "      <td>0.064424</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>0.204223</td>\n",
       "      <td>0.150988</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.132774</td>\n",
       "      <td>0.489471</td>\n",
       "      <td>0.674074</td>\n",
       "      <td>0.872385</td>\n",
       "      <td>0.528902</td>\n",
       "      <td>0.034976</td>\n",
       "      <td>0.068318</td>\n",
       "      <td>0.104849</td>\n",
       "      <td>0.725261</td>\n",
       "      <td>0.208304</td>\n",
       "      <td>0.050511</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731455</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.101806</td>\n",
       "      <td>0.094471</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.159694</td>\n",
       "      <td>0.517151</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.878661</td>\n",
       "      <td>0.520231</td>\n",
       "      <td>0.064868</td>\n",
       "      <td>0.077548</td>\n",
       "      <td>0.133858</td>\n",
       "      <td>0.711395</td>\n",
       "      <td>0.185593</td>\n",
       "      <td>0.083090</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>0.805738</td>\n",
       "      <td>0.005678</td>\n",
       "      <td>0.187208</td>\n",
       "      <td>0.086090</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.114015</td>\n",
       "      <td>0.441979</td>\n",
       "      <td>0.690741</td>\n",
       "      <td>0.826360</td>\n",
       "      <td>0.492775</td>\n",
       "      <td>0.052435</td>\n",
       "      <td>0.050821</td>\n",
       "      <td>0.098632</td>\n",
       "      <td>0.784206</td>\n",
       "      <td>0.261097</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>0.047697</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.462610</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>0.194498</td>\n",
       "      <td>0.152607</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.854051</td>\n",
       "      <td>0.937060</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.240586</td>\n",
       "      <td>0.095376</td>\n",
       "      <td>0.384382</td>\n",
       "      <td>0.681778</td>\n",
       "      <td>0.239536</td>\n",
       "      <td>0.717829</td>\n",
       "      <td>0.320441</td>\n",
       "      <td>0.941931</td>\n",
       "      <td>0.747508</td>\n",
       "      <td>0.968454</td>\n",
       "      <td>0.094060</td>\n",
       "      <td>0.963737</td>\n",
       "      <td>0.113237</td>\n",
       "      <td>0.148818</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.795102</td>\n",
       "      <td>0.900527</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.232218</td>\n",
       "      <td>0.122832</td>\n",
       "      <td>0.382876</td>\n",
       "      <td>0.795261</td>\n",
       "      <td>0.219644</td>\n",
       "      <td>0.637877</td>\n",
       "      <td>0.159406</td>\n",
       "      <td>0.929911</td>\n",
       "      <td>0.776359</td>\n",
       "      <td>0.948874</td>\n",
       "      <td>0.152658</td>\n",
       "      <td>0.940149</td>\n",
       "      <td>0.100905</td>\n",
       "      <td>0.119428</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.857171</td>\n",
       "      <td>0.994048</td>\n",
       "      <td>0.118519</td>\n",
       "      <td>0.196653</td>\n",
       "      <td>0.111272</td>\n",
       "      <td>0.307691</td>\n",
       "      <td>0.701862</td>\n",
       "      <td>0.176129</td>\n",
       "      <td>0.800442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.954787</td>\n",
       "      <td>0.704850</td>\n",
       "      <td>0.864489</td>\n",
       "      <td>0.151241</td>\n",
       "      <td>0.925292</td>\n",
       "      <td>0.169232</td>\n",
       "      <td>0.098858</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.716455</td>\n",
       "      <td>0.773606</td>\n",
       "      <td>0.140741</td>\n",
       "      <td>0.259414</td>\n",
       "      <td>0.143064</td>\n",
       "      <td>0.364686</td>\n",
       "      <td>0.576084</td>\n",
       "      <td>0.152093</td>\n",
       "      <td>0.581643</td>\n",
       "      <td>0.374699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.822928</td>\n",
       "      <td>0.935625</td>\n",
       "      <td>0.139390</td>\n",
       "      <td>0.867558</td>\n",
       "      <td>0.156128</td>\n",
       "      <td>0.183374</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.732501</td>\n",
       "      <td>0.784826</td>\n",
       "      <td>0.161111</td>\n",
       "      <td>0.301255</td>\n",
       "      <td>0.177746</td>\n",
       "      <td>0.350782</td>\n",
       "      <td>0.463611</td>\n",
       "      <td>0.159552</td>\n",
       "      <td>0.624192</td>\n",
       "      <td>0.238240</td>\n",
       "      <td>0.888828</td>\n",
       "      <td>0.768404</td>\n",
       "      <td>0.940553</td>\n",
       "      <td>0.104835</td>\n",
       "      <td>0.835914</td>\n",
       "      <td>0.179183</td>\n",
       "      <td>0.166157</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     한국은행_기준금리     KOSPI    KOSDAQ    CD_91일   국고채_10년  회사채_3년_AA  \\\n",
       "0     0.684211  0.150785  0.523719  0.651852  0.905858   0.557803   \n",
       "1     0.736842  0.138142  0.512937  0.670370  0.843096   0.533237   \n",
       "2     0.736842  0.132774  0.489471  0.674074  0.872385   0.528902   \n",
       "3     0.736842  0.159694  0.517151  0.685185  0.878661   0.520231   \n",
       "4     0.736842  0.114015  0.441979  0.690741  0.826360   0.492775   \n",
       "..         ...       ...       ...       ...       ...        ...   \n",
       "189   0.052632  0.854051  0.937060  0.083333  0.240586   0.095376   \n",
       "190   0.105263  0.795102  0.900527  0.100000  0.232218   0.122832   \n",
       "191   0.105263  0.857171  0.994048  0.118519  0.196653   0.111272   \n",
       "192   0.157895  0.716455  0.773606  0.140741  0.259414   0.143064   \n",
       "193   0.157895  0.732501  0.784826  0.161111  0.301255   0.177746   \n",
       "\n",
       "     KOSPI_거래대금_일평균  KOSDAQ_거래대금_일평균  KOSPI_주가이익비율_3  기관투자자_순매수    개인_순매수  \\\n",
       "0          0.133986         0.128401        0.110236   0.660705  0.172458   \n",
       "1          0.073347         0.090498        0.108993   0.721468  0.211550   \n",
       "2          0.034976         0.068318        0.104849   0.725261  0.208304   \n",
       "3          0.064868         0.077548        0.133858   0.711395  0.185593   \n",
       "4          0.052435         0.050821        0.098632   0.784206  0.261097   \n",
       "..              ...              ...             ...        ...       ...   \n",
       "189        0.384382         0.681778        0.239536   0.717829  0.320441   \n",
       "190        0.382876         0.795261        0.219644   0.637877  0.159406   \n",
       "191        0.307691         0.701862        0.176129   0.800442  0.000000   \n",
       "192        0.364686         0.576084        0.152093   0.581643  0.374699   \n",
       "193        0.350782         0.463611        0.159552   0.624192  0.238240   \n",
       "\n",
       "      투자자_예탁금  파생상품거래_예수금_1        RP  위탁매매_미수금  신용융자_잔고_2  거래대금_일평균_CALL_옵션  \\\n",
       "0    0.080661      0.019894  0.000487  0.994870   0.005722          0.212613   \n",
       "1    0.064424      0.008211  0.001543  1.000000   0.005518          0.204223   \n",
       "2    0.050511      0.001297  0.000000  0.731455   0.004496          0.101806   \n",
       "3    0.083090      0.002425  0.003498  0.805738   0.005678          0.187208   \n",
       "4    0.043003      0.047697  0.003992  0.462610   0.004466          0.194498   \n",
       "..        ...           ...       ...       ...        ...               ...   \n",
       "189  0.941931      0.747508  0.968454  0.094060   0.963737          0.113237   \n",
       "190  0.929911      0.776359  0.948874  0.152658   0.940149          0.100905   \n",
       "191  0.954787      0.704850  0.864489  0.151241   0.925292          0.169232   \n",
       "192  1.000000      0.822928  0.935625  0.139390   0.867558          0.156128   \n",
       "193  0.888828      0.768404  0.940553  0.104835   0.835914          0.179183   \n",
       "\n",
       "     거래대금_일평균_PUT_옵션  KOSPI_BINARY  \n",
       "0           0.125723           0.0  \n",
       "1           0.150988           0.0  \n",
       "2           0.094471           1.0  \n",
       "3           0.086090           0.0  \n",
       "4           0.152607           0.0  \n",
       "..               ...           ...  \n",
       "189         0.148818           0.0  \n",
       "190         0.119428           1.0  \n",
       "191         0.098858           0.0  \n",
       "192         0.183374           1.0  \n",
       "193         0.166157           1.0  \n",
       "\n",
       "[194 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "\n",
    "def make_dataset(data, label, window_size):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        feature_list.append(np.array(data.iloc[i:i+window_size]))\n",
    "        label_list.append(np.array(label.iloc[i+window_size-1])) # -1을 한 이유: 이미 한달 뒤 변동 여부가 KOSPI_BINARY 칼럼에 값으로 들어가 있음\n",
    "    return np.array(feature_list), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'KOSPI_BINARY'\n",
    "feature_cols = list(df.columns)\n",
    "feature_cols.remove(target_col)\n",
    "label_cols = [target_col]\n",
    "\n",
    "train_feature = df[feature_cols]\n",
    "train_label = df[label_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature, train_label = make_dataset(train_feature, train_label, window_size)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_feature, train_label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((147, 10, 18), (37, 10, 18))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\loven\\Anaconda3\\envs\\allocation\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\loven\\Anaconda3\\envs\\allocation\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\loven\\Anaconda3\\envs\\allocation\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\loven\\Anaconda3\\envs\\allocation\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(16, \n",
    "               input_shape=(train_feature.shape[1], train_feature.shape[2]), \n",
    "               activation='relu',\n",
    "               return_sequences=False))\n",
    "          )\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 147 samples, validate on 37 samples\n",
      "WARNING:tensorflow:From C:\\Users\\loven\\Anaconda3\\envs\\allocation\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.2285\n",
      "Epoch 00001: val_loss improved from inf to 0.20187, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 3s 19ms/sample - loss: 0.2261 - val_loss: 0.2019\n",
      "Epoch 2/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.1886\n",
      "Epoch 00002: val_loss improved from 0.20187 to 0.16668, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 1ms/sample - loss: 0.1848 - val_loss: 0.1667\n",
      "Epoch 3/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.1614\n",
      "Epoch 00003: val_loss improved from 0.16668 to 0.14600, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 769us/sample - loss: 0.1586 - val_loss: 0.1460\n",
      "Epoch 4/200\n",
      "112/147 [=====================>........] - ETA: 0s - loss: 0.1416\n",
      "Epoch 00004: val_loss improved from 0.14600 to 0.13502, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 885us/sample - loss: 0.1426 - val_loss: 0.1350\n",
      "Epoch 5/200\n",
      " 96/147 [==================>...........] - ETA: 0s - loss: 0.1370\n",
      "Epoch 00005: val_loss improved from 0.13502 to 0.13074, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 896us/sample - loss: 0.1340 - val_loss: 0.1307\n",
      "Epoch 6/200\n",
      " 80/147 [===============>..............] - ETA: 0s - loss: 0.1331\n",
      "Epoch 00006: val_loss improved from 0.13074 to 0.13008, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 1ms/sample - loss: 0.1330 - val_loss: 0.1301\n",
      "Epoch 7/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.1322\n",
      "Epoch 00007: val_loss improved from 0.13008 to 0.12936, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 1ms/sample - loss: 0.1322 - val_loss: 0.1294\n",
      "Epoch 8/200\n",
      " 96/147 [==================>...........] - ETA: 0s - loss: 0.1328\n",
      "Epoch 00008: val_loss improved from 0.12936 to 0.12844, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 964us/sample - loss: 0.1312 - val_loss: 0.1284\n",
      "Epoch 9/200\n",
      " 96/147 [==================>...........] - ETA: 0s - loss: 0.1352\n",
      "Epoch 00009: val_loss improved from 0.12844 to 0.12775, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 923us/sample - loss: 0.1300 - val_loss: 0.1278\n",
      "Epoch 10/200\n",
      " 96/147 [==================>...........] - ETA: 0s - loss: 0.1260\n",
      "Epoch 00010: val_loss improved from 0.12775 to 0.12756, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 914us/sample - loss: 0.1291 - val_loss: 0.1276\n",
      "Epoch 11/200\n",
      "112/147 [=====================>........] - ETA: 0s - loss: 0.1269\n",
      "Epoch 00011: val_loss improved from 0.12756 to 0.12737, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 838us/sample - loss: 0.1286 - val_loss: 0.1274\n",
      "Epoch 12/200\n",
      " 80/147 [===============>..............] - ETA: 0s - loss: 0.1298\n",
      "Epoch 00012: val_loss did not improve from 0.12737\n",
      "147/147 [==============================] - 0s 857us/sample - loss: 0.1280 - val_loss: 0.1275\n",
      "Epoch 13/200\n",
      "144/147 [============================>.] - ETA: 0s - loss: 0.1279\n",
      "Epoch 00013: val_loss improved from 0.12737 to 0.12714, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 821us/sample - loss: 0.1277 - val_loss: 0.1271\n",
      "Epoch 14/200\n",
      "144/147 [============================>.] - ETA: 0s - loss: 0.1269\n",
      "Epoch 00014: val_loss improved from 0.12714 to 0.12671, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 1ms/sample - loss: 0.1272 - val_loss: 0.1267\n",
      "Epoch 15/200\n",
      " 96/147 [==================>...........] - ETA: 0s - loss: 0.1279\n",
      "Epoch 00015: val_loss improved from 0.12671 to 0.12642, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 1ms/sample - loss: 0.1267 - val_loss: 0.1264\n",
      "Epoch 16/200\n",
      "144/147 [============================>.] - ETA: 0s - loss: 0.1257\n",
      "Epoch 00016: val_loss improved from 0.12642 to 0.12610, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 1ms/sample - loss: 0.1267 - val_loss: 0.1261\n",
      "Epoch 17/200\n",
      " 96/147 [==================>...........] - ETA: 0s - loss: 0.1238\n",
      "Epoch 00017: val_loss improved from 0.12610 to 0.12597, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 954us/sample - loss: 0.1255 - val_loss: 0.1260\n",
      "Epoch 18/200\n",
      " 96/147 [==================>...........] - ETA: 0s - loss: 0.1236\n",
      "Epoch 00018: val_loss did not improve from 0.12597\n",
      "147/147 [==============================] - 0s 778us/sample - loss: 0.1255 - val_loss: 0.1260\n",
      "Epoch 19/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.1260\n",
      "Epoch 00019: val_loss improved from 0.12597 to 0.12547, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 833us/sample - loss: 0.1253 - val_loss: 0.1255\n",
      "Epoch 20/200\n",
      "112/147 [=====================>........] - ETA: 0s - loss: 0.1234\n",
      "Epoch 00020: val_loss improved from 0.12547 to 0.12516, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 920us/sample - loss: 0.1247 - val_loss: 0.1252\n",
      "Epoch 21/200\n",
      "144/147 [============================>.] - ETA: 0s - loss: 0.1253\n",
      "Epoch 00021: val_loss did not improve from 0.12516\n",
      "147/147 [==============================] - 0s 940us/sample - loss: 0.1247 - val_loss: 0.1253\n",
      "Epoch 22/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.1241\n",
      "Epoch 00022: val_loss did not improve from 0.12516\n",
      "147/147 [==============================] - 0s 579us/sample - loss: 0.1239 - val_loss: 0.1253\n",
      "Epoch 23/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.1228\n",
      "Epoch 00023: val_loss did not improve from 0.12516\n",
      "147/147 [==============================] - 0s 605us/sample - loss: 0.1235 - val_loss: 0.1252\n",
      "Epoch 24/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.1232\n",
      "Epoch 00024: val_loss improved from 0.12516 to 0.12507, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 811us/sample - loss: 0.1236 - val_loss: 0.1251\n",
      "Epoch 25/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.1217\n",
      "Epoch 00025: val_loss improved from 0.12507 to 0.12497, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 822us/sample - loss: 0.1234 - val_loss: 0.1250\n",
      "Epoch 26/200\n",
      "112/147 [=====================>........] - ETA: 0s - loss: 0.1230\n",
      "Epoch 00026: val_loss improved from 0.12497 to 0.12438, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 890us/sample - loss: 0.1225 - val_loss: 0.1244\n",
      "Epoch 27/200\n",
      " 80/147 [===============>..............] - ETA: 0s - loss: 0.1256\n",
      "Epoch 00027: val_loss improved from 0.12438 to 0.12408, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 1ms/sample - loss: 0.1220 - val_loss: 0.1241\n",
      "Epoch 28/200\n",
      " 64/147 [============>.................] - ETA: 0s - loss: 0.1268\n",
      "Epoch 00028: val_loss improved from 0.12408 to 0.12400, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 1ms/sample - loss: 0.1219 - val_loss: 0.1240\n",
      "Epoch 29/200\n",
      "144/147 [============================>.] - ETA: 0s - loss: 0.1221\n",
      "Epoch 00029: val_loss did not improve from 0.12400\n",
      "147/147 [==============================] - 0s 1ms/sample - loss: 0.1217 - val_loss: 0.1246\n",
      "Epoch 30/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.1215\n",
      "Epoch 00030: val_loss did not improve from 0.12400\n",
      "147/147 [==============================] - 0s 595us/sample - loss: 0.1213 - val_loss: 0.1246\n",
      "Epoch 31/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.1214\n",
      "Epoch 00031: val_loss did not improve from 0.12400\n",
      "147/147 [==============================] - 0s 594us/sample - loss: 0.1207 - val_loss: 0.1241\n",
      "Epoch 32/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.1209\n",
      "Epoch 00032: val_loss did not improve from 0.12400\n",
      "147/147 [==============================] - 0s 582us/sample - loss: 0.1204 - val_loss: 0.1242\n",
      "Epoch 33/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.1210\n",
      "Epoch 00033: val_loss improved from 0.12400 to 0.12379, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 764us/sample - loss: 0.1198 - val_loss: 0.1238\n",
      "Epoch 34/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.1186\n",
      "Epoch 00034: val_loss improved from 0.12379 to 0.12365, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 908us/sample - loss: 0.1190 - val_loss: 0.1236\n",
      "Epoch 35/200\n",
      " 80/147 [===============>..............] - ETA: 0s - loss: 0.1162\n",
      "Epoch 00035: val_loss improved from 0.12365 to 0.12360, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 1ms/sample - loss: 0.1188 - val_loss: 0.1236\n",
      "Epoch 36/200\n",
      " 80/147 [===============>..............] - ETA: 0s - loss: 0.1203\n",
      "Epoch 00036: val_loss improved from 0.12360 to 0.12303, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 1ms/sample - loss: 0.1183 - val_loss: 0.1230\n",
      "Epoch 37/200\n",
      " 80/147 [===============>..............] - ETA: 0s - loss: 0.1157\n",
      "Epoch 00037: val_loss improved from 0.12303 to 0.12301, saving model to tmp_checkpoint.h5\n",
      "147/147 [==============================] - 0s 1ms/sample - loss: 0.1177 - val_loss: 0.1230\n",
      "Epoch 38/200\n",
      "144/147 [============================>.] - ETA: 0s - loss: 0.1179\n",
      "Epoch 00038: val_loss did not improve from 0.12301\n",
      "147/147 [==============================] - 0s 933us/sample - loss: 0.1173 - val_loss: 0.1233\n",
      "Epoch 39/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.1174\n",
      "Epoch 00039: val_loss did not improve from 0.12301\n",
      "147/147 [==============================] - 0s 575us/sample - loss: 0.1173 - val_loss: 0.1233\n",
      "Epoch 40/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.1154\n",
      "Epoch 00040: val_loss did not improve from 0.12301\n",
      "147/147 [==============================] - 0s 614us/sample - loss: 0.1163 - val_loss: 0.1237\n",
      "Epoch 41/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.1153\n",
      "Epoch 00041: val_loss did not improve from 0.12301\n",
      "147/147 [==============================] - 0s 565us/sample - loss: 0.1152 - val_loss: 0.1248\n",
      "Epoch 42/200\n",
      "128/147 [=========================>....] - ETA: 0s - loss: 0.1146\n",
      "Epoch 00042: val_loss did not improve from 0.12301\n",
      "147/147 [==============================] - 0s 582us/sample - loss: 0.1151 - val_loss: 0.1256\n"
     ]
    }
   ],
   "source": [
    "loss = Huber()\n",
    "optimizer = Adam(0.0005)\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "checkpoint = ModelCheckpoint(weight_name, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=200, \n",
    "                    batch_size=16,\n",
    "                    validation_data=(x_valid, y_valid), \n",
    "                    callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최근 데이터에 모델 적용 -> 결과값 저장(이 결과가 자산배분 시 활용됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>한국은행_기준금리</th>\n",
       "      <th>KOSPI</th>\n",
       "      <th>KOSDAQ</th>\n",
       "      <th>CD_91일</th>\n",
       "      <th>국고채_10년</th>\n",
       "      <th>회사채_3년_AA</th>\n",
       "      <th>KOSPI_거래대금_일평균</th>\n",
       "      <th>KOSDAQ_거래대금_일평균</th>\n",
       "      <th>KOSPI_주가이익비율_3</th>\n",
       "      <th>기관투자자_순매수</th>\n",
       "      <th>개인_순매수</th>\n",
       "      <th>투자자_예탁금</th>\n",
       "      <th>파생상품거래_예수금_1</th>\n",
       "      <th>RP</th>\n",
       "      <th>위탁매매_미수금</th>\n",
       "      <th>신용융자_잔고_2</th>\n",
       "      <th>거래대금_일평균_CALL_옵션</th>\n",
       "      <th>거래대금_일평균_PUT_옵션</th>\n",
       "      <th>KOSPI_BINARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.150785</td>\n",
       "      <td>0.523719</td>\n",
       "      <td>0.651852</td>\n",
       "      <td>0.905858</td>\n",
       "      <td>0.557803</td>\n",
       "      <td>0.133986</td>\n",
       "      <td>0.128401</td>\n",
       "      <td>0.110236</td>\n",
       "      <td>0.660705</td>\n",
       "      <td>0.172458</td>\n",
       "      <td>0.080661</td>\n",
       "      <td>0.019894</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.994870</td>\n",
       "      <td>0.005722</td>\n",
       "      <td>0.212613</td>\n",
       "      <td>0.125723</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.138142</td>\n",
       "      <td>0.512937</td>\n",
       "      <td>0.670370</td>\n",
       "      <td>0.843096</td>\n",
       "      <td>0.533237</td>\n",
       "      <td>0.073347</td>\n",
       "      <td>0.090498</td>\n",
       "      <td>0.108993</td>\n",
       "      <td>0.721468</td>\n",
       "      <td>0.211550</td>\n",
       "      <td>0.064424</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>0.204223</td>\n",
       "      <td>0.150988</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.132774</td>\n",
       "      <td>0.489471</td>\n",
       "      <td>0.674074</td>\n",
       "      <td>0.872385</td>\n",
       "      <td>0.528902</td>\n",
       "      <td>0.034976</td>\n",
       "      <td>0.068318</td>\n",
       "      <td>0.104849</td>\n",
       "      <td>0.725261</td>\n",
       "      <td>0.208304</td>\n",
       "      <td>0.050511</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731455</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.101806</td>\n",
       "      <td>0.094471</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.159694</td>\n",
       "      <td>0.517151</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.878661</td>\n",
       "      <td>0.520231</td>\n",
       "      <td>0.064868</td>\n",
       "      <td>0.077548</td>\n",
       "      <td>0.133858</td>\n",
       "      <td>0.711395</td>\n",
       "      <td>0.185593</td>\n",
       "      <td>0.083090</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>0.805738</td>\n",
       "      <td>0.005678</td>\n",
       "      <td>0.187208</td>\n",
       "      <td>0.086090</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.114015</td>\n",
       "      <td>0.441979</td>\n",
       "      <td>0.690741</td>\n",
       "      <td>0.826360</td>\n",
       "      <td>0.492775</td>\n",
       "      <td>0.052435</td>\n",
       "      <td>0.050821</td>\n",
       "      <td>0.098632</td>\n",
       "      <td>0.784206</td>\n",
       "      <td>0.261097</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>0.047697</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.462610</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>0.194498</td>\n",
       "      <td>0.152607</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.854051</td>\n",
       "      <td>0.937060</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.240586</td>\n",
       "      <td>0.095376</td>\n",
       "      <td>0.384382</td>\n",
       "      <td>0.681778</td>\n",
       "      <td>0.239536</td>\n",
       "      <td>0.717829</td>\n",
       "      <td>0.320441</td>\n",
       "      <td>0.941931</td>\n",
       "      <td>0.747508</td>\n",
       "      <td>0.968454</td>\n",
       "      <td>0.094060</td>\n",
       "      <td>0.963737</td>\n",
       "      <td>0.113237</td>\n",
       "      <td>0.148818</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.795102</td>\n",
       "      <td>0.900527</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.232218</td>\n",
       "      <td>0.122832</td>\n",
       "      <td>0.382876</td>\n",
       "      <td>0.795261</td>\n",
       "      <td>0.219644</td>\n",
       "      <td>0.637877</td>\n",
       "      <td>0.159406</td>\n",
       "      <td>0.929911</td>\n",
       "      <td>0.776359</td>\n",
       "      <td>0.948874</td>\n",
       "      <td>0.152658</td>\n",
       "      <td>0.940149</td>\n",
       "      <td>0.100905</td>\n",
       "      <td>0.119428</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.857171</td>\n",
       "      <td>0.994048</td>\n",
       "      <td>0.118519</td>\n",
       "      <td>0.196653</td>\n",
       "      <td>0.111272</td>\n",
       "      <td>0.307691</td>\n",
       "      <td>0.701862</td>\n",
       "      <td>0.176129</td>\n",
       "      <td>0.800442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.954787</td>\n",
       "      <td>0.704850</td>\n",
       "      <td>0.864489</td>\n",
       "      <td>0.151241</td>\n",
       "      <td>0.925292</td>\n",
       "      <td>0.169232</td>\n",
       "      <td>0.098858</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.716455</td>\n",
       "      <td>0.773606</td>\n",
       "      <td>0.140741</td>\n",
       "      <td>0.259414</td>\n",
       "      <td>0.143064</td>\n",
       "      <td>0.364686</td>\n",
       "      <td>0.576084</td>\n",
       "      <td>0.152093</td>\n",
       "      <td>0.581643</td>\n",
       "      <td>0.374699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.822928</td>\n",
       "      <td>0.935625</td>\n",
       "      <td>0.139390</td>\n",
       "      <td>0.867558</td>\n",
       "      <td>0.156128</td>\n",
       "      <td>0.183374</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.732501</td>\n",
       "      <td>0.784826</td>\n",
       "      <td>0.161111</td>\n",
       "      <td>0.301255</td>\n",
       "      <td>0.177746</td>\n",
       "      <td>0.350782</td>\n",
       "      <td>0.463611</td>\n",
       "      <td>0.159552</td>\n",
       "      <td>0.624192</td>\n",
       "      <td>0.238240</td>\n",
       "      <td>0.888828</td>\n",
       "      <td>0.768404</td>\n",
       "      <td>0.940553</td>\n",
       "      <td>0.104835</td>\n",
       "      <td>0.835914</td>\n",
       "      <td>0.179183</td>\n",
       "      <td>0.166157</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     한국은행_기준금리     KOSPI    KOSDAQ    CD_91일   국고채_10년  회사채_3년_AA  \\\n",
       "0     0.684211  0.150785  0.523719  0.651852  0.905858   0.557803   \n",
       "1     0.736842  0.138142  0.512937  0.670370  0.843096   0.533237   \n",
       "2     0.736842  0.132774  0.489471  0.674074  0.872385   0.528902   \n",
       "3     0.736842  0.159694  0.517151  0.685185  0.878661   0.520231   \n",
       "4     0.736842  0.114015  0.441979  0.690741  0.826360   0.492775   \n",
       "..         ...       ...       ...       ...       ...        ...   \n",
       "189   0.052632  0.854051  0.937060  0.083333  0.240586   0.095376   \n",
       "190   0.105263  0.795102  0.900527  0.100000  0.232218   0.122832   \n",
       "191   0.105263  0.857171  0.994048  0.118519  0.196653   0.111272   \n",
       "192   0.157895  0.716455  0.773606  0.140741  0.259414   0.143064   \n",
       "193   0.157895  0.732501  0.784826  0.161111  0.301255   0.177746   \n",
       "\n",
       "     KOSPI_거래대금_일평균  KOSDAQ_거래대금_일평균  KOSPI_주가이익비율_3  기관투자자_순매수    개인_순매수  \\\n",
       "0          0.133986         0.128401        0.110236   0.660705  0.172458   \n",
       "1          0.073347         0.090498        0.108993   0.721468  0.211550   \n",
       "2          0.034976         0.068318        0.104849   0.725261  0.208304   \n",
       "3          0.064868         0.077548        0.133858   0.711395  0.185593   \n",
       "4          0.052435         0.050821        0.098632   0.784206  0.261097   \n",
       "..              ...              ...             ...        ...       ...   \n",
       "189        0.384382         0.681778        0.239536   0.717829  0.320441   \n",
       "190        0.382876         0.795261        0.219644   0.637877  0.159406   \n",
       "191        0.307691         0.701862        0.176129   0.800442  0.000000   \n",
       "192        0.364686         0.576084        0.152093   0.581643  0.374699   \n",
       "193        0.350782         0.463611        0.159552   0.624192  0.238240   \n",
       "\n",
       "      투자자_예탁금  파생상품거래_예수금_1        RP  위탁매매_미수금  신용융자_잔고_2  거래대금_일평균_CALL_옵션  \\\n",
       "0    0.080661      0.019894  0.000487  0.994870   0.005722          0.212613   \n",
       "1    0.064424      0.008211  0.001543  1.000000   0.005518          0.204223   \n",
       "2    0.050511      0.001297  0.000000  0.731455   0.004496          0.101806   \n",
       "3    0.083090      0.002425  0.003498  0.805738   0.005678          0.187208   \n",
       "4    0.043003      0.047697  0.003992  0.462610   0.004466          0.194498   \n",
       "..        ...           ...       ...       ...        ...               ...   \n",
       "189  0.941931      0.747508  0.968454  0.094060   0.963737          0.113237   \n",
       "190  0.929911      0.776359  0.948874  0.152658   0.940149          0.100905   \n",
       "191  0.954787      0.704850  0.864489  0.151241   0.925292          0.169232   \n",
       "192  1.000000      0.822928  0.935625  0.139390   0.867558          0.156128   \n",
       "193  0.888828      0.768404  0.940553  0.104835   0.835914          0.179183   \n",
       "\n",
       "     거래대금_일평균_PUT_옵션  KOSPI_BINARY  \n",
       "0           0.125723           0.0  \n",
       "1           0.150988           0.0  \n",
       "2           0.094471           1.0  \n",
       "3           0.086090           0.0  \n",
       "4           0.152607           0.0  \n",
       "..               ...           ...  \n",
       "189         0.148818           0.0  \n",
       "190         0.119428           1.0  \n",
       "191         0.098858           0.0  \n",
       "192         0.183374           1.0  \n",
       "193         0.166157           1.0  \n",
       "\n",
       "[194 rows x 19 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 최신 데이터셋 구축 ##\n",
    "\n",
    "# start_date를 넉넉히 20일 전으로 설정\n",
    "start_date = datetime.date.today() - datetime.timedelta(20)\n",
    "start_date = datetime.date.isoformat(start_date)\n",
    "\n",
    "# 코스피 전일 종가 가져오기\n",
    "kospi = fdr.DataReader('KS11', start_date)\n",
    "\n",
    "# 가장 최근 일자의 코스피 종가\n",
    "kospi_yd = kospi.loc[kospi.index[-1], 'Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>한국은행_기준금리</th>\n",
       "      <th>KOSPI</th>\n",
       "      <th>KOSDAQ</th>\n",
       "      <th>CD_91일</th>\n",
       "      <th>국고채_10년</th>\n",
       "      <th>회사채_3년_AA</th>\n",
       "      <th>KOSPI_거래대금_일평균</th>\n",
       "      <th>KOSDAQ_거래대금_일평균</th>\n",
       "      <th>KOSPI_주가이익비율_3</th>\n",
       "      <th>기관투자자_순매수</th>\n",
       "      <th>개인_순매수</th>\n",
       "      <th>투자자_예탁금</th>\n",
       "      <th>파생상품거래_예수금_1</th>\n",
       "      <th>RP</th>\n",
       "      <th>위탁매매_미수금</th>\n",
       "      <th>신용융자_잔고_2</th>\n",
       "      <th>거래대금_일평균_CALL_옵션</th>\n",
       "      <th>거래대금_일평균_PUT_옵션</th>\n",
       "      <th>KOSPI_BINARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.732501</td>\n",
       "      <td>0.784826</td>\n",
       "      <td>0.161111</td>\n",
       "      <td>0.301255</td>\n",
       "      <td>0.177746</td>\n",
       "      <td>0.350782</td>\n",
       "      <td>0.463611</td>\n",
       "      <td>0.159552</td>\n",
       "      <td>0.624192</td>\n",
       "      <td>0.23824</td>\n",
       "      <td>0.888828</td>\n",
       "      <td>0.768404</td>\n",
       "      <td>0.940553</td>\n",
       "      <td>0.104835</td>\n",
       "      <td>0.835914</td>\n",
       "      <td>0.179183</td>\n",
       "      <td>0.166157</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     한국은행_기준금리     KOSPI    KOSDAQ    CD_91일   국고채_10년  회사채_3년_AA  \\\n",
       "193   0.157895  0.732501  0.784826  0.161111  0.301255   0.177746   \n",
       "\n",
       "     KOSPI_거래대금_일평균  KOSDAQ_거래대금_일평균  KOSPI_주가이익비율_3  기관투자자_순매수   개인_순매수  \\\n",
       "193        0.350782         0.463611        0.159552   0.624192  0.23824   \n",
       "\n",
       "      투자자_예탁금  파생상품거래_예수금_1        RP  위탁매매_미수금  신용융자_잔고_2  거래대금_일평균_CALL_옵션  \\\n",
       "193  0.888828      0.768404  0.940553  0.104835   0.835914          0.179183   \n",
       "\n",
       "     거래대금_일평균_PUT_옵션  KOSPI_BINARY  \n",
       "193         0.166157           1.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>한국은행_기준금리</th>\n",
       "      <th>KOSPI</th>\n",
       "      <th>KOSDAQ</th>\n",
       "      <th>CD_91일</th>\n",
       "      <th>국고채_10년</th>\n",
       "      <th>회사채_3년_AA</th>\n",
       "      <th>KOSPI_거래대금_일평균</th>\n",
       "      <th>KOSDAQ_거래대금_일평균</th>\n",
       "      <th>KOSPI_주가이익비율_3</th>\n",
       "      <th>기관투자자_순매수</th>\n",
       "      <th>개인_순매수</th>\n",
       "      <th>투자자_예탁금</th>\n",
       "      <th>파생상품거래_예수금_1</th>\n",
       "      <th>RP</th>\n",
       "      <th>위탁매매_미수금</th>\n",
       "      <th>신용융자_잔고_2</th>\n",
       "      <th>거래대금_일평균_CALL_옵션</th>\n",
       "      <th>거래대금_일평균_PUT_옵션</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.157895</td>\n",
       "      <td>-0.475588</td>\n",
       "      <td>0.784826</td>\n",
       "      <td>0.161111</td>\n",
       "      <td>0.301255</td>\n",
       "      <td>0.177746</td>\n",
       "      <td>0.350782</td>\n",
       "      <td>0.463611</td>\n",
       "      <td>0.159552</td>\n",
       "      <td>0.624192</td>\n",
       "      <td>0.23824</td>\n",
       "      <td>0.888828</td>\n",
       "      <td>0.768404</td>\n",
       "      <td>0.940553</td>\n",
       "      <td>0.104835</td>\n",
       "      <td>0.835914</td>\n",
       "      <td>0.179183</td>\n",
       "      <td>0.166157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   한국은행_기준금리     KOSPI    KOSDAQ    CD_91일   국고채_10년  회사채_3년_AA  \\\n",
       "0   0.157895 -0.475588  0.784826  0.161111  0.301255   0.177746   \n",
       "\n",
       "   KOSPI_거래대금_일평균  KOSDAQ_거래대금_일평균  KOSPI_주가이익비율_3  기관투자자_순매수   개인_순매수  \\\n",
       "0        0.350782         0.463611        0.159552   0.624192  0.23824   \n",
       "\n",
       "    투자자_예탁금  파생상품거래_예수금_1        RP  위탁매매_미수금  신용융자_잔고_2  거래대금_일평균_CALL_옵션  \\\n",
       "0  0.888828      0.768404  0.940553  0.104835   0.835914          0.179183   \n",
       "\n",
       "   거래대금_일평균_PUT_옵션  \n",
       "0         0.166157  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df에서 가장 최근 데이터 가져오기\n",
    "df_recent = df.loc[[df.index[-1]]]\n",
    "df_recent.drop('KOSPI_BINARY', axis = 1, inplace=True)\n",
    "df_recent.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 코스피 종가 수정\n",
    "df_recent['KOSPI'] = (df_recent['KOSPI'] - scaler_kospi['min'])/(scaler_kospi['max'] - scaler_kospi['min'])\n",
    "df_recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "transpose expects a vector of size 2. But input(1) is a vector of size 3\n\t [[{{node sequential/bidirectional/transpose_2}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23900\\960173097.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 예측\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\allocation\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1076\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m           \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1078\u001b[1;33m           callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\allocation\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\allocation\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\allocation\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: transpose expects a vector of size 2. But input(1) is a vector of size 3\n\t [[{{node sequential/bidirectional/transpose_2}}]]"
     ]
    }
   ],
   "source": [
    "# weight 로딩\n",
    "model.load_weights(weight_name)\n",
    "\n",
    "# 예측\n",
    "pred = model.predict(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26460"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recent_np = df_recent.to_numpy()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1511f024a4443f7e5f12ae3dcc5576141864db34ee7c246ddb8e44c131c19028"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('prediction')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
